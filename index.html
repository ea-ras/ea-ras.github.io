<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  <style>
    .centered-image {
      display: block;
      margin-left: auto;
      margin-right: auto;
    }
    .grid-container {
      display: grid;
      grid-template-columns: 1fr 1fr; /* 两列布局 */
      grid-gap: 10px; /* 列之间的间距 */
    }

    .item {
      width: 100%; /* 视频宽度 */
      height: auto; /* 视频高度 */
    }
  </style>

  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>EA-RAS</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <!-- <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">EA-RAS: Towards Efficient and Accurate End-to-End Reconstruction of Anatomical Skeleton </h1>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EA-RAS: Towards Efficient and Accurate End-to-End Reconstruction of Anatomical Skeleton </h1>
          <div class="is-size-5 publication-authors">
            <!-- Paper authors -->
            <span class="author-block"> Zhiheng Peng, </span>
              <span class="author-block"> Kai Zhao, </span>
                <span class="author-block"> Li Ma, </span>
                  <span class="author-block"> Siyu Xia, </span>
                    <span class="author-block"> Changjie Fan, </span>
                      <span class="author-block"> Weijian Shang, </span>
                        <span class="author-block"> Wei Jing </span>
                </div>

                <div class="is-size-5 publication-authors">
                  <span class="author-block">Netease XuanYuan Robot<br>2024</span>
                  <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                </div>

                <div class="column has-text-centered">
                  <div class="publication-links">
                       <!-- Arxiv PDF link -->
                    <span class="link-block">
                      <a href="https://arxiv.org/pdf/2409.01555" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- Supplementary PDF link -->
                  <span class="link-block">
                    <a href="/post/data.html" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-video"></i>
                    </span>
                    <span>Additional Data</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/ea-ras/EA-RAS" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2409.01555" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
              Efficient, accurate and low-cost estimation of human skeletal information is crucial for a range of applications such as biology education and human-computer interaction. However, current simple skeleton models, which are typically based on 2D-
            3D joint points, fall short in terms of anatomical fidelity, restricting their utility in fields. On the other hand, more complex models while anatomically precise, are hindered by sophisticate multi-stage processing and the need for extra data like skin meshes,
            making them unsuitable for real-time applications. To this end, we propose the STIO (See Through the Inside and Outside), a single-stage, lightweight, and plug-and-play anatomical skeleton estimator that can provide real-time, accurate anatomically real-
            istic skeletons with arbitrary pose using only a single RGB image input. Additionally, STIO estimates the conventional human mesh model explicitly, which not only enhances the functionality but also leverages the outside skin information by integrating
            features into the inside skeleton modeling process. In this work, we also develop a progressive training strategy and integrated it with an enhanced optimization process, enabling the network to obtain initial weights using only a small skin dataset and
            achieve self-supervision in skeleton reconstruction. Besides, we also provide an optional lightweight post-processing optimization strategy to further improve accuracy for scenarios that prioritize precision over real-time processing. The experiments
            demonstrated that our regression method is over 800 times faster than existing methods, meeting real-time requirements. Additionally, the post-processing optimization strategy provided can enhance reconstruction accuracy by over 50% and achieve
            a speed increase of more than 7 times.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3">Quick Start (comming soon)</h2>
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/quick.mp4"
        type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Code and Contents are comming soon</h2>
        
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <span class="author-block">
        <h2 class="title is-3"><a href="/post/data.html">Additional Result</a></h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="grid-container">
          <div class="item item-video1">
            <video poster="" id="video1" autoplay controls muted loop height="100%">
              <source src="static/videos/kongfu.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="video2" autoplay controls muted loop height="100%">
              <source src="static/videos/case1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video3">
            <video poster="" id="video3" autoplay controls muted loop height="100%">
              <source src="static/videos/case2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video4">
            <video poster="" id="video4" autoplay controls muted loop height="100%">
              <source src="static/videos/case3.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video5">
            <video poster="" id="video5" autoplay controls muted loop height="100%">
              <source src="static/videos/case4.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{peng2024earasefficientaccurateendtoend,
      title={EA-RAS: Towards Efficient and Accurate End-to-End Reconstruction of Anatomical Skeleton}, 
      author={Zhiheng Peng and Kai Zhao and Xiaoran Chen and Li Ma and Siyu Xia and Changjie Fan and Weijian Shang and Wei Jing},
      year={2024},
      eprint={2409.01555},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.01555}, 
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->


</body>
